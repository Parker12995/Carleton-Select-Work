hist(rbeta(1000, pa1, pb1))
hist(rbeta(1000, pa2, pb2))
hist(rbeta(1000, pa1, pb1))
hist(rbeta(1000, pa2, pb2))
pm1<-pa1/(pa1+pb1)
pm2<-pa2/(pa2+pb2)
pm2
pm1
yn<-40
nn<-100
yn<-40
nn<-100
pa1<-a1+yn
pb1<-b1+nn-yn
pa2<-a2+yn
pb2<-b2+nn-yn
pm1<-pa1/(pa1+pb1)
pm2<-pa2/(pa2+pb2)
pm1
pm2
hist(rbeta(1000, pa1, pb1))
hist(rbeta(1000, pa2, pb2))
#b
y<-4
n<-10
pa1<-a1+y
pb1<-b1+n-y
pa2<-a2+y
pb2<-b2+n-y
pm1<-pa1/(pa1+pb1)
pm2<-pa2/(pa2+pb2)
pm1
pm2
hist(rbeta(1000, pa1, pb1))
hist(rbeta(1000, pa2, pb2))
knitr::opts_chunk$set(echo = TRUE)
devtools::source_gist("https://gist.github.com/aloy/e1fcefb4e04c349777f030762dfdb301")
m1<-9/10
m2<-45/50
samp1<-9+10
samp2<-45+5
m1<-9/10
m2<-45/50
samp1<-9+10
samp2<-45+5
m1
m2
samp1
samp2
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(dplyr)
hist(scores$score)
scores <- read.csv("http://aloy.rbind.io/data/test_scores.csv")
mu<-mean(scores$score)
sd<-sd(scores$score)
mu #mean of data
sd #sd of data
hist(scores$score)
set.seed(100)
y<-rnorm(1000, 86, 7) #randomly generated 1000 points from mu prior
hist(y)
set.seed(100)
z<-runif(1000, 0, 12) #randomly generated 1000 points from sigma prior
hist(z)
set.seed(100)
sim_scores<-rnorm(1000, y, z) #randomly generated 1000 points from joint prior distribution
hist(sim_scores) #histogram of simulated points in prior
mean(sim_scores) #mean of joint prior
sd(sim_scores) #sd of joint prior
hist(scores$score)
ggplot(scores, aes(score)) + geom_histogram()
ggplot(scores, aes(score)) + geom_histogram(bins = 20)
ggplot(scores, aes(score)) + geom_histogram(bins = 10)
ggplot(scores, aes(score)) + geom_histogram(bins = 10, color = black)
ggplot(scores, aes(score)) + geom_histogram(bins = 10, color = "black")
hist(scores$score)
ggplot(scores, aes(score)) + geom_histogram(bins = 7, color = "black")
ggplot(scores, aes(score)) + geom_histogram(bins = 7, color = "black", fill = "whtie")
ggplot(scores, aes(score)) + geom_histogram(bins = 7, color = "black", fill = "white")
ggplot(scores, aes(score)) + geom_histogram(bins = 7, color = "black", fill = "white") +
labs(title = "Figure 1: Histogram of Stat 120 Test Scores", xlab = "Test Score", ylab = "Frequency")
ggplot(scores, aes(score)) + geom_histogram(bins = 7, color = "black", fill = "white") +
labs(title = "Figure 1: Histogram of Stat 120 Test Scores", x = "Test Score", ylab = "Frequency")
ggplot(scores, aes(score)) + geom_histogram(bins = 7, color = "black", fill = "white") +
labs(title = "Figure 1: Histogram of Stat 120 Test Scores", x = "Test Score", y = "Frequency")
ggplot(scores, aes(score)) + geom_histogram(bins = 7, color = "black", fill = "white") +
labs(title = "Figure 1: Histogram of Stat 120 Test Scores", x = "Test Score", y = "Count")
hist(sim_scores) #histogram of simulated points in prior
scores <- read.csv("http://aloy.rbind.io/data/test_scores.csv")
mu<-mean(scores$score)
sd<-sd(scores$score)
mu #mean of data
sd #sd of data
hist(scores$score)
ggplot(scores, aes(score)) + geom_histogram(bins = 7, color = "black", fill = "white") +
labs(title = "Figure 1: Histogram of Stat 120 Test Scores", x = "Test Score", y = "Count")
set.seed(100)
y<-rnorm(1000, 86, 7) #randomly generated 1000 points from mu prior
hist(y)
set.seed(100)
z<-runif(1000, 0, 12) #randomly generated 1000 points from sigma prior
hist(z)
set.seed(100)
sim_scores<-rnorm(1000, y, z) #randomly generated 1000 points from joint prior distribution
hist(sim_scores) #histogram of simulated points in prior
mean(sim_scores) #mean of joint prior
sd(sim_scores) #sd of joint prior
ggplot(sim_scores)
ggplot(sim_scores) + geom_histogram()
ggplot(sim_scores, aes(sim_scores)) + geom_histogram()
hist(sim_scores) #histogram of simulated points in prior
hist(sim_scores, fill = "white") #histogram of simulated points in prior
ggplot(scores, aes(score)) + geom_histogram(bins = 7, color = "black", fill = "white") +
labs(title = "Figure 1: Histogram of Stat 120 Test Scores", x = "Test Score", y = "Count")
hist(scores$score) + title("Figure 1: Histogram of Stat 120 Test Scores")
hist(scores$score, main = "Figure 1: Histogram of Stat 120 Test Scores")
hist(scores$score, main = "Figure 1: Histogram of Stat 120 Test Scores", xlab = "Test Scores", ylab = "Count")
hist(scores$score, main = "Figure 1: Frequency of Stat 120 Test Scores in given data set", xlab = "Test Scores", ylab = "Count")
hist(sim_scores, main = "Figure 2: Frequency of exam scores in simulated prior distribution",
xlab = "Simulated Scores", ylab = "Count") #histogram of simulated points in prior
hist(scores$score, main = "Figure 1: Frequency of Stat 120 Test Scores in given data set", xlab = "Test Scores", ylab = "Count")
hist(sim_scores, main = "Figure 2: Frequency of exam scores in simulated prior distribution",
xlab = "Simulated Scores", ylab = "Count") #histogram of simulated points in prior
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(dplyr)
#grid approximation for posterior
param_grid <- expand.grid(
mu = seq(from = 40, to = 130, length.out = 1000),
sigma = seq(from = 1, to = 12, length.out = 1000)
) #creating grid based over coordinate plane
log_lik_norm <- function(x, mu, sigma) {
sum(dnorm(x, mean = mu, sd = sigma, log = TRUE))
} #create vectorized log likelihood function
log_lik_norm <- Vectorize(log_lik_norm, vectorize.args = c("mu", "sigma"))
posterior <- param_grid %>%
mutate(
log_prior = dnorm(mu, 86, 7, log = TRUE) +
dunif(sigma, 0, 12, log = TRUE),
log_lik = log_lik_norm(scores$score, mu = mu, sigma = sigma),
log_post = log_prior + log_lik,
unstd_post = exp(log_post - max(log_post)),
post = unstd_post / sum(unstd_post)
) #Evaluate log prior and log-likelihood on the grid and derive the posterior
posterior_draws <- slice_sample(
posterior,
n = 1e4,
replace = TRUE,
weight_by = post
)
pmu<-mean(posterior_draws$mu)
psig<-mean(posterior_draws$sigma)
pmu #mean of mu posterior
psig #mean of sigma posterior
quantile(posterior_draws$mu, #marginal quantiles
probs = c(0.05, 0.95))
quantile(posterior_draws$sigma,
probs = c(0.05, 0.95))
qnorm(c(0.025, 0.975), pmu, psig) #credible interval for posterior distribution with mu = pmu and sigma = psig
posterior_draws
posterior
param_grid
hist(scores$score, main = "Figure 1: Frequency of Stat 120 Test Scores in given data set",
xlab = "Test Scores", ylab = "Count")
mu<-mean(scores$score)
mu #mean of data
set.seed(100)
y<-rnorm(1000, 86, 7) #randomly generated 1000 points from mu prior
hist(y)
set.seed(100)
z<-runif(1000, 0, 12) #randomly generated 1000 points from sigma prior
hist(z)
set.seed(100)
sim_scores<-rnorm(1000, y, z) #randomly generated 1000 points from joint prior distribution
hist(sim_scores, main = "Figure 2: Frequency of exam scores in simulated prior distribution",
xlab = "Simulated Scores", ylab = "Count")
set.seed(100)
y<-rnorm(1000, 86, 7) #randomly generated 1000 points from mu prior
hist(y)
set.seed(100)
z<-runif(1000, 0, 12) #randomly generated 1000 points from sigma prior
hist(z)
set.seed(100)
sim_scores<-rnorm(1000, y, z) #randomly generated 1000 points from joint prior distribution
hist(sim_scores, main = "Figure 2: Frequency of exam scores in simulated prior distribution",
xlab = "Simulated Scores", ylab = "Count") #histogram of simulated points in prior
mean(sim_scores) #mean of joint prior
sd(sim_scores) #sd of joint prior
set.seed(100)
y<-rnorm(1000, 86, 15) #randomly generated 1000 points from mu prior
hist(y)
set.seed(100)
z<-runif(1000, 0, 12) #randomly generated 1000 points from sigma prior
hist(z)
set.seed(100)
sim_scores<-rnorm(1000, y, z) #randomly generated 1000 points from joint prior distribution
hist(sim_scores, main = "Figure 2: Frequency of exam scores in simulated prior distribution",
xlab = "Simulated Scores", ylab = "Count")
min(sim_scores)
set.seed(100)
y<-rnorm(1000, 86, 7) #randomly generated 1000 points from mu prior
hist(y)
set.seed(100)
z<-runif(1000, 0, 12) #randomly generated 1000 points from sigma prior
hist(z)
set.seed(100)
sim_scores<-rnorm(1000, y, z) #randomly generated 1000 points from joint prior distribution
hist(sim_scores, main = "Figure 2: Frequency of exam scores in simulated prior distribution",
xlab = "Simulated Scores", ylab = "Count") #histogram of simulated points in prior
mean(sim_scores) #mean of joint prior
sd(sim_scores) #sd of joint prior
range(sim_scores
)
set.seed(100)
y<-rnorm(1000, 86, 7) #randomly generated 1000 points from mu prior
hist(y)
set.seed(100)
z<-runif(1000, 0, 20) #randomly generated 1000 points from sigma prior
hist(z)
set.seed(100)
sim_scores<-rnorm(1000, y, z) #randomly generated 1000 points from joint prior distribution
hist(sim_scores, main = "Figure 2: Frequency of exam scores in simulated prior distribution",
xlab = "Simulated Scores", ylab = "Count") #histogram of simulated points in prior
mean(sim_scores) #mean of joint prior
sd(sim_scores) #sd of joint prior
set.seed(100)
y<-rnorm(1000, 86, 7) #randomly generated 1000 points from mu prior
hist(y)
set.seed(100)
z<-runif(1000, 0, 12) #randomly generated 1000 points from sigma prior
hist(z)
set.seed(100)
sim_scores<-rnorm(1000, y, z) #randomly generated 1000 points from joint prior distribution
hist(sim_scores, main = "Figure 2: Frequency of exam scores in simulated prior distribution",
xlab = "Simulated Scores", ylab = "Count") #histogram of simulated points in prior
mean(sim_scores) #mean of joint prior
sd(sim_scores) #sd of joint prior
set.seed(100)
y<-rnorm(1000, 86, 7) #randomly generated 1000 points from mu prior
hist(y)
set.seed(100)
z<-runif(1000, 0, 20) #randomly generated 1000 points from sigma prior
hist(z)
set.seed(100)
sim_scores<-rnorm(1000, y, z) #randomly generated 1000 points from joint prior distribution
hist(sim_scores, main = "Figure 2: Frequency of exam scores in simulated prior distribution",
xlab = "Simulated Scores", ylab = "Count") #histogram of simulated points in prior
mean(sim_scores) #mean of joint prior
sd(sim_scores) #sd of joint prior
set.seed(100)
y<-rnorm(1000, 86, 7) #randomly generated 1000 points from mu prior
hist(y)
set.seed(100)
z<-runif(1000, 0, 12) #randomly generated 1000 points from sigma prior
hist(z)
set.seed(100)
sim_scores<-rnorm(1000, y, z) #randomly generated 1000 points from joint prior distribution
hist(sim_scores, main = "Figure 2: Frequency of exam scores in simulated prior distribution",
xlab = "Simulated Scores", ylab = "Count") #histogram of simulated points in prior
mean(sim_scores) #mean of joint prior
#grid approximation for posterior
param_grid <- expand.grid(
mu = seq(from = 40, to = 130, length.out = 1000),
sigma = seq(from = 1, to = 12, length.out = 1000)
) #creating grid based over coordinate plane
log_lik_norm <- function(x, mu, sigma) {
sum(dnorm(x, mean = mu, sd = sigma, log = TRUE))
} #create vectorized log likelihood function
log_lik_norm <- Vectorize(log_lik_norm, vectorize.args = c("mu", "sigma"))
posterior <- param_grid %>%
mutate(
log_prior = dnorm(mu, 86, 7, log = TRUE) +
dunif(sigma, 0, 12, log = TRUE),
log_lik = log_lik_norm(scores$score, mu = mu, sigma = sigma),
log_post = log_prior + log_lik,
unstd_post = exp(log_post - max(log_post)),
post = unstd_post / sum(unstd_post)
) #Evaluate log prior and log-likelihood on the grid and derive the posterior
posterior_draws <- slice_sample(
posterior,
n = 1e4,
replace = TRUE,
weight_by = post
)
posterior_draws
param_grid
?expand.grid
qnorm(c(0.025, 0.975), pmu, psig) #credible interval for posterior distribution with mu = pmu and sigma = psig
posterior_draws
mean(log_lik)
mean(posterior_draws$log_lik)
posterior_draws
pll<-mean(posterior_draws$log_lik) #mean of log likelihood
ppost<-mean(posterior_draws$post) #mean of post
pll
ppost
quantile(posterior_draws$mu, #marginal quantiles
probs = c(0.05, 0.95))
quantile(posterior_draws$sigma,
probs = c(0.05, 0.95))
quantile(posterior_draws$mu, #marginal quantiles
probs = c(0.05, 0.95))
knitr::opts_chunk$set(echo = TRUE)
read.csv("Crime_Data.csv")
setwd("~/Desktop/carleton_comps_22_23/data/original")
read.csv("Crime_Data.csv")
Crime_Data<-read.csv("Crime_Data.csv")
View(Crime_Data)
dim(Crime_Data)
colnames(Crime_Data)
knitr::opts_chunk$set(echo = TRUE)
library(readr)
library(ggplot2)
library(dplyr)
use_of_force <- read_csv("../../data/original/Police_Use_of_Force.csv")
#Count of NA values in each column
na_count <- use_of_force %>% summarise(across(everything(), ~ sum(is.na(.))))
na_count
unique(use_of_force$ForceType)
use_of_force %>%
slice_min(EventAge, n = 1)
sum(use_of_force$EventAge <= 0, na.rm = TRUE)
dim(Crime_Data) #
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(tidyverse)
neighborhood.df <- table(data$Neighborhood) %>% as.data.frame()
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(tidyverse)
data <- read.csv("/Users/ayaklos/Documents/GitHub/carleton_comps_22_23/data/original/Crime_Data.csv")
colnames(Crime_Data)
#X=longitude, Y=Latitude
str(Crime_Data)
colnames(Crime_Data)
table(Crime_Data$Type)
table(Crime_Data$Type, NA = TRUE)
table(Crime_Data$NIBRS_Crime_Against)
table(is.na(Crime_Data))
table(Crime_Data$Offense_Category)
library(ggplot2)
library(tidyverse)
ggplot(Crime_Data, aes(x=Neighborhood)) +
geom_bar(position = fill) +
ggplot(Crime_Data, aes(x=Neighborhood)) +
geom_bar(position = fill)
ggplot(Crime_Data, aes(x=Neighborhood)) +
geom_bar(aes(position = fill))
ggplot(Crime_Data, aes(x=Neighborhood, fill = Offense_Category)) +
geom_bar()
ggplot(Crime_Data, aes(x=Neighborhood))
ggplot(Crime_Data, aes(x=Neighborhood)) +
geom_bar()
Nhood_top <- data[order(Crime_Data$Neighborhood, decreasing = TRUE),]
str(Crime_Data$Neighborhood)
Nhood_top <- table(data$Neighborhood) %>% as.data.frame() %>% data[order(Crime_Data$Neighborhood, decreasing = TRUE),]
Nhood_top <- table(data$Neighborhood) %>% as.data.frame()  data[order(Crime_Data$Neighborhood, decreasing = TRUE),]
Nhood_top <- table(Crime_Data$Neighborhood) %>% as.data.frame()  data[order(Crime_Data$Neighborhood, decreasing = TRUE),]
Nhood_top <- table(Crime_Data$Neighborhood) %>% as.data.frame()
Nhood_top<-data[order(Crime_Data$Neighborhood, decreasing = TRUE),]
library(dplyr)
Nhood_top <- Crime_Data %>%
arrange(desc(Neighborhood))
Crime_Data %>%
arrange(desc(Neighborhood))
table(Crime_Data$Neighborhood)
mean(rowSums(is.na(Crime_Data)) > 0)
table(is.na(Crime_Data))
ggplot(Crime_Data, aes(x=Crime_Count)) +
geom_bar()
neighborhood.df <- table(Crime_Data$Neighborhood) %>% as.data.frame()
ggplot(neighborhood.df, aes(x = reorder(Var1,-Freq), y = Freq)) +
geom_bar(stat = "identity") +
labs(x = "Neighborhood") +
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
ggplot(Crime_Data, aes(x=Neighborhood, fill = Offense_Category))
ggplot(Crime_Data, aes(x=Neighborhood, fill = Offense_Category)) +
geom_bar()
nhood <- table(Crime_Data$Neighborhood) %>% as.data.frame()
nhood <- table(Crime_Data$Neighborhood) %>% as.data.frame()
nhood %>%
arrange()
nhood %>%
reorder(Var1, - Freq)
nhood %>%
reorder(Var1)
nhood %>%
reorder(Freq)
names(which.max(nhood))
names(which.max(table(nhood)))
ggplot(Crime_Data, aes(x=Crime_Count)) +
geom_bar()
ggplot(Crime_Data, aes(x=Offense_Category)) +
geom_bar()
ggplot(Crime_Data, aes(x=Offense_Category)) +
geom_bar()+
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
ggplot(Crime_Data, aes(x=Offense_Category)) +
geom_bar()+
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
nhood <- table(Crime_Data$Neighborhood) %>% as.data.frame()
ggplot(Crime_Data, aes(x=Neighborhood, fill = Offense_Category)) +
geom_bar()
off_type <- table(Crime_Data$Offense_Category) %>% as.data.frame()
ggplot(off_type, aes(x= reorder(Var1, -Freq))) +
geom_bar()+
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
ggplot(off_type, aes(x= reorder(Var1, -Freq))) +
geom_bar(stat = "identity")+
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
ggplot(off_type, aes(x= reorder(Var1, -Freq), y = Freq)) +
geom_bar()+
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
ggplot(off_type, aes(x= reorder(Var1, -Freq), y = Freq)) +
geom_bar(stat = "identity")+
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
top_by_n <- Crime_Data %>%
filter(Offense_Category == "Larceny/Theft Offenses" | Offense_Category == "Shots Fired Calls" | Offense_Category == "Assult Offenses")
Crime_Data %>%
filter(Offense_Category == "Larceny/Theft Offenses" | Offense_Category == "Shots Fired Calls" | Offense_Category == "Assult Offenses")
ggplot(top_by_n, aes(x = Offense_Category, fill = Neighborhood)) +
geom_bar()
ggplot(top_by_n, aes(x = Neighborhood, fill = Offense_Category)) +
geom_bar()
ggplot(top_by_n, aes(x = Neighborhood, fill = "Offense_Category")) +
geom_bar()
Crime_Data %>%
filter(Offense_Category == "Larceny/Theft Offenses" | Offense_Category == "Shots Fired Calls" | Offense_Category == "Assult Offenses")
View(top_by_n)
top_by_n <- Crime_Data %>%
filter(Offense_Category == "Larceny/Theft Offenses"| Offense_Category == "Assult Offenses")
ggplot(top_by_n, aes(x = Neighborhood, fill = Offense_Category)) +
geom_bar()
VIew(top_by_n)
View(top_by_n)
ggplot(off_type, aes(x= reorder(Var1, -Freq), y = Freq)) +
geom_bar(stat = "identity")+
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
top_by_n <- Crime_Data %>%
filter(Offense_Category == "Larceny/Theft Offenses"| Offense_Category == "Assault Offenses")
View(top_by_n)
ggplot(off_type, aes(x= reorder(Var1, -Freq), y = Freq)) +
geom_bar(stat = "identity")+
theme(axis.text.x = element_text(angle = 45, vjust = 0.5, hjust=1))
ggplot(CrimeA_type, aes(x= reorder(Var1, -Freq), y = Freq)) +
geom_bar(stat = "identity")+
theme(axis.text.x = element_text(angle = 45, vjust = 0.5, hjust=1))
CrimeA_type <- table(Crime_Data$NIBRS_Crime_Against) %>% as.data.frame()
ggplot(CrimeA_type, aes(x= reorder(Var1, -Freq), y = Freq)) +
geom_bar(stat = "identity")+
theme(axis.text.x = element_text(angle = 45, vjust = 0.5, hjust=1))
nhood <- table(Crime_Data$Neighborhood) %>% as.data.frame()
ggplot(nhood, aes(x= reorder(Var1, -Freq), y = Freq)) +
geom_bar(stat = "identity")+
theme(axis.text.x = element_text(angle = 45, vjust = 0.5, hjust=1))
top3<- Crime_Data %>%
filter(Neighborhood == "Downtown West" | Neighborhood == "Jordan" | Neighborhood == "Whittier")
ggplot(top3, aes(x=Neighborhood))
ggplot(top3, aes(x=Neighborhood, fill = Offense_Category)) +
geom_bar()
ggplot(top3, aes(x=Neighborhood, fill = NIBRS_Crime_Against)) +
geom_bar()
ggplot(CrimeA_type, aes(x= reorder(Var1, -Freq), y = Freq)) +
geom_bar(stat = "identity")+
theme(axis.text.x = element_text(angle = 45, vjust = 0.5, hjust=1))
ggplot(off_type, aes(x= reorder(Var1, -Freq), y = Freq)) +
geom_bar(stat = "identity")+
theme(axis.text.x = element_text(angle = 45, vjust = 0.5, hjust=1))
top3<- Crime_Data %>%
filter(Neighborhood == "Downtown West" | Neighborhood == "Jordan" | Neighborhood == "Whittier")  %>%
filter(Offense_Category == "Larceny/Theft Offenses")
ggplot(top3, aes(x=Neighborhood, fill = NIBRS_Crime_Against)) +
geom_bar()
top3<- Crime_Data %>%
filter(Neighborhood == "Downtown West" | Neighborhood == "Jordan" | Neighborhood == "Whittier")
ggplot(top3, aes(x=Neighborhood, fill = NIBRS_Crime_Against)) +
geom_bar()
View(Crime_Data)
Crime_Data %>%
filter(X==0, Y==0)
NAs<-Crime_Data %>%
filter(X==0, Y==0)
table(NAs$X)
NAs<-Crime_Data %>%
filter(X==0, Y==0)
NAs<-Crime_Data %>%
filter(X==0, Y==0) %>%
count()
Crime_Data %>%
filter(X==0, Y==0) %>%
count()
Crime_Data %>%
filter(X==0, Y==0) %>%
count() %>%
table(Neighborhood)
NAs<-Crime_Data %>%
filter(X==0, Y==0)
count(NAs)
table(NAs$Neighborhood)
table(NAs$Orecinct)
table(NAs$Precinct)
count(NAs$Precinct)
table(NAs$Precinct)
ggplot(top3, aes(x=Neighborhood, fill = NIBRS_Crime_Against)) +
geom_bar()
ggplot(top3, aes(x=Neighborhood, fill = Offense_Category)) +
geom_bar()
ggplot(top3, aes(x=Neighborhood, fill = NIBRS_Crime_Against)) +
geom_bar()
count(NAs)
table(NAs$Neighborhood)
