---
title: "LGCP Simple Example"
output: pdf_document
date: "2023-03-02"
---

# Libraries

```{r}
library(ggplot2)
library(spatstat)
```

```{r}

```



# Generate synthetic dataset

```{r}
set.seed(42)

# generate observed points

observed_pts <- data.frame(runif(1000, min = 0, max = 1.5), runif(1000, min = 0, max = 1.5))
colnames(observed_pts) = c("x", "y")

# assume there are 3x3 = 9 tracts
# assume there are 3 covariates in total: temperature, population, air conditioning rating

# assign census tracks

regions <- c()
for (i in 1:nrow(observed_pts)) {
  pt <- observed_pts[i, ]
  x <- pt[1]
  y <- pt[2]
  if (x > 0 & x <= 0.5) {
    if (y > 0 & y <= 0.5) {
      region <- 1
    } else if (y > 0.5 & y <= 1) {
      region <- 2
    } else if (y > 1) {
      region <- 3
    }
  } else if (x > 0.5 & x <= 1) {
    if (y > 0 & y <= 0.5) {
      region <- 4
    } else if (y > 0.5 & y <= 1) {
      region <- 5
    } else if (y > 1) {
      region <- 6
    }
  } else if (x > 1) {
    if (y > 0 & y <= 0.5) {
      region <- 7
    } else if (y > 0.5 & y <= 1) {
      region <- 8
    } else if (y > 1) {
      region <- 9
    }
  }
  regions <- append(regions, region) 
}

# generate covariate values for each census track

covs_for_regions <- matrix(rnorm(9 * 3) * 3, nrow = 9)

# overlay

covs_over_pts <- data.frame()
for (i in 1:length(regions)) {
  covs_over_pts <- rbind(covs_over_pts, covs_for_regions[regions[i], ])
}

# sanity check

dim(covs_over_pts)
```

```{r}

```






























```{r}
library(nimble)
library(sp)
library(tidyverse)
library(fields)  # for rdist

######################load data###########################################################################

#bind in another script sim_points and the overlayed data below
sim_points <- read.csv("~/Desktop/projects/carleton_comps_22_23/data/working/integration_points/494points_coord.csv")
over_sim_points_census <- read.csv("~/Desktop/projects/carleton_comps_22_23/data/working/over_sim_points_census.csv")
over_uof_census <- read.csv("~/Desktop/projects/carleton_comps_22_23/data/working/overlay_pointdatasets_censusdata/over_uof_census.csv")
minn_tracts.sf <- read.csv("~/Desktop/projects/carleton_comps_22_23/data/working/minn_tracts_sf.csv")
knots <- read.csv("~/Desktop/projects/carleton_comps_22_23/src/zhihan/lgcp_likelihood_inputs/knots.csv")
#add original uof information to over_uof_census in another script as well

over_uof_census$perc_white <- over_uof_census$total_white/over_uof_census$total_pop
over_uof_census$perc_poverty <- over_uof_census$below_pov_level/over_uof_census$total_pop

over_sim_points_census$perc_white <- over_sim_points_census$total_white/over_sim_points_census$total_pop
over_sim_points_census$perc_poverty <- over_sim_points_census$below_pov_level/over_sim_points_census$total_pop

############################################################################################################
n_uof = nrow(over_uof_census)
n_sim = nrow(sim_points)
n_knots <- nrow(knots)

sim_covs <- as.matrix(over_sim_points_census[,c("perc_white", "perc_poverty")])
covs <- as.matrix(over_uof_census[,c("perc_white", "perc_poverty")])
XB <- vector(length=n_uof)
XB_int <- vector(length=n_sim)

sigma <- 1
phi <- 0.10
kernel <- function(p1, p2, sigma, phi) {
  sigma^2 * exp(- rdist(p1, p2) / phi)
}  # TODO: replace this with nimble func

# ===== GP =====
knots_cov <- kernel(knots, knots, sigma=sigma, phi=phi)
observed_pts_vs_knots_cov <- kernel(over_uof_census[,1:2], knots, sigma=sigma, phi=phi)
integration_pts_vs_knots_cov <- kernel(sim_points, knots, sigma=sigma, phi=phi)
# gp_on_knots <- mvrnorm(1, mu=numeric(nrow(knots)), Sigma=knots_cov)
# gp_on_observed_pts <- observed_pts_vs_knots_cov %*% solve(knots_cov) %*% gp_on_knots
# gp_on_integration_pts <- integration_pts_vs_knots_cov %*% solve(knots_cov) %*% gp_on_knots

#build the model
code <- nimbleCode({
  beta0 ~ dnorm(0, sd = 1000)
  beta1 ~ dnorm(0, sd = 1000)
  beta2 ~ dnorm(0, sd = 1000)
  sigma ~ dinvgamma(2, 0.5)
  
  XB[1:n_uof] <- beta0 + beta1*covs[,1] + beta2*covs[,2]
  XB_int[1:n_sim] <- beta0 + beta1*sim_covs[,1] + beta2*sim_covs[,2]
  
  #include prior for gaussian process--dmvnorm
  #parameters--sigma, fixed parameter phi, distance matrix for knots
  #transform gaussian process over knots to dimension of integration points and to data points (do two separately)
  
  gp_on_knots[1:n_knots] ~ dmnorm(knots_mean[1:n_knots], cov=knots_cov[1:n_knots, 1:n_knots])
  gp_on_observed_pts[1:n_uof] <- observed_pts_vs_knots_cov[1:n_uof, 1:n_knots] %*% inverse(knots_cov[1:n_knots, 1:n_knots]) %*% gp_on_knots[1:n_knots]  # TODO: too slow? reduce # knots
  # gp_on_integration_pts[1:n_knots <- 
  # TODO
  
  int <- (area / n_sim) * sum(XB_int[1:n_sim])  # TODO: add GP on integration points here
})

Rmodel <- nimbleModel(code, data = list(), #add the distance matrices in data as well
                      inits = list(beta0 = 1,
                                   beta1 = 1,
                                   beta2 = 1,
                                   sigma = 1),
                      constants = list(sim_covs = sim_covs, covs = covs, area = sum(minn_tracts.sf$tract_area),
                                   # XB = XB, XB_int = XB_int, 
                                   n_uof = n_uof, n_sim = n_sim,
                                   knots_mean = numeric(n_knots),
                                   knots_cov = knots_cov, observed_pts_vs_knots_cov = observed_pts_vs_knots_cov,
                                   # integration_pts_vs_knots_cov = integration_pts_vs_knots_cov,
                                   n_knots = n_knots
                                   ))

llFun <- nimbleFunction(
  setup = function(model) { },
  run = function() {
    
    # beta0 <- model$beta0
    # beta1 <- model$beta1
    # beta2 <- model$beta2
    # sigma <- model$sigma
    
    # XB <- model$XB
    # XB_int <- model$XB_int

     # area <- model$area
     # m <- model$m
    
    #int <- (area / m) * sum(beta0 + beta1*sim_cov1 + beta2*sim_cov2) 

    #ll <- sum(beta0 + beta1*cov1 + beta2*cov2) - int
    ll <- sum(model$XB + model$gp_on_observed_pts) - model$int
    
    returnType(double())
    return(ll[1])
  }
)

RllFun <- llFun(Rmodel)

# TODO: nodes added here vs nodes added later 
# (if the ways of adding samplers are equivalent; post_predictive sampler might not take into account ll)

mcmcConf <- configureMCMC(Rmodel, nodes = c("beta0", "beta1", "beta2", "sigma", "gp_on_knots"), print=T)
mcmcConf$printSamplers()

#mcmcConf <- configureMCMC(Rmodel, nodes = NULL)
# 
mcmcConf$addSampler(target = "beta0", type = "RW_llFunction",
                    control = list(llFunction = RllFun, includesTarget = FALSE))

mcmcConf$addSampler(target = "beta1", type = "RW_llFunction",
                    control = list(llFunction = RllFun, includesTarget = FALSE))

mcmcConf$addSampler(target = "beta2", type = "RW_llFunction",
                    control = list(llFunction = RllFun, includesTarget = FALSE))

mcmcConf$addSampler(target = "sigma", type = "RW_llFunction",
                    control = list(llFunction = RllFun, includesTarget = FALSE))
mcmcConf$addSampler(target = "gp_on_knots", type = "RW_llFunction",
                    control = list(llFunction = RllFun, includesTarget = FALSE))

mcmcConf$printSamplers()

# Rmodel$initializeInfo()

Rmcmc <- buildMCMC(mcmcConf)

runMCMC(Rmcmc, 100)

samples1 <- as.matrix(Rmcmc$mvSamples)

plot(samples1[, 4], type="l")

#check with trace plot
```

```{r}
plot(samples1[, 194])
```

