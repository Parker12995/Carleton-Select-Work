#load Boston census tracts
load(url("https://www.math.carleton.edu/ckelling/spat_data/boston_tracts_full.Rdata"))
#Model 1: x + y
fit1 <- ppm(Q = crime_ppp, trend = ~x + y )
#plot(fit1) #note that if you try to run this, you will likely get an error before rescaling
#look at scale of x and y values
head(crime_ppp$x)
#need to rescale data, otherwise we get a numerical error
rescale_factor <- 100000
crime_ppp_rescaled <- rescale(crime_ppp, rescale_factor)
#look at new scale
head(crime_ppp_rescaled$x)
#Model 1: x + y
fit1 <- ppm(Q = crime_ppp_rescaled, trend = ~x + y)
summary(fit1)
plot(fit1)
fit2 <- ppm(Q = crime_ppp_rescaled, trend = ~x + y + I(x * y))
summary(fit2)
plot(fit2)
fit3 <- ppm(Q = crime_ppp_rescaled, trend = ~x + y + I(x * y) + I(x^2) + I(y^2))
summary(fit3)
plot(fit3)
#make a grid
lattice <- expand.grid(Long = seq(boston_tracts@bbox[1,1],
boston_tracts@bbox[1,2],length.out = 100),
Lat = seq(boston_tracts@bbox[2,1],
boston_tracts@bbox[2,2],length.out = 100))
dim(lattice)
plot(lattice)
#find if the points are in the region
sp_lattice <- lattice
coordinates(sp_lattice) <- ~Long+Lat
proj4string(sp_lattice) <- proj4string(boston_tracts)
overlap_set <- over(sp_lattice, boston_tracts)
#remove lattice points not in Boston
lattice <- lattice[!(is.na(overlap_set$GEOID)),]
plot(lattice)
#combine with the rest of the Census data
lattice <- cbind(lattice, overlap_set[-which(is.na(overlap_set$GEOID)),])
#plot of gridded Census data
ggplot() + geom_point(data = lattice, aes(Long,Lat, col = perc_renter)) +
scale_color_distiller(palette = "Spectral")
#remove grid points with NA for perc_renter
lattice <- lattice %>% filter(!is.na(perc_renter))
#plot of gridded Census data without NA values
ggplot() + geom_point(data = lattice, aes(Long,Lat, col = perc_renter))+
scale_color_distiller(palette = "Spectral")
#assign projection to lattice
coordinates(lattice) <- ~Long+Lat
proj4string(lattice) <- proj4string(boston_tracts)
#change from SpatialPointsDataFrame to SpatialPixelsDataFrame
class(lattice)
gridded(lattice) = TRUE
class(lattice)
#then change to SpatialGridDataFrame
lattice_grid <- as(lattice, "SpatialGridDataFrame")
class(lattice_grid)
#make into an "im" object
image(lattice_grid["perc_renter"]) #plot first
percrenter_im <- as(lattice_grid["perc_renter"], "im") #convert to im
#Packages:
library(tidyverse)
library(sp)
library(ggmap)
library(spatstat)
library(sf)
library(maptools)
library(splancs)
library(philentropy)
library(geosphere)
#make into an "im" object
image(lattice_grid["perc_renter"]) #plot first
percrenter_im <- as(lattice_grid["perc_renter"], "im") #convert to im
plot(percrenter_im)
# Chunk 1
set.seed(3)
library(rgdal)
library(spatstat)
library(raster)
library(tigris)
library(ggplot2)
library(broom)
library(tidyverse)
library(ggmap)
library(spdep)
library(maditr)
library(maptools)
# Chunk 2
load(url("https://www.math.carleton.edu/ckelling/spat_data/bost_entertain_ppp.Rdata"))
# Chunk 3
entertain_ppp <- rescale(entertain_ppp, 1000000)
sigma <- 0.008
kernel_density1 <- density(entertain_ppp, sigma = sigma)
plot(kernel_density1, main = "KDE: Boston Entertainment License Data")
plot(entertain_ppp, add = T)
# Chunk 4
#estimate lambda
summary(entertain_ppp)$intensity
#another way to estimate lambda
ppm(entertain_ppp, ~1)
# Chunk 5
fit1 <- ppm(Q = entertain_ppp, trend = ~x + y)
plot(fit1)
plot(fit2)
fit2 <- ppm(Q = entertain_ppp, trend = ~x + y + I(x * y))
fit3 <- ppm(Q = entertain_ppp, trend = ~x + y + I(x * y) + I(x^2) + I(y^2))
boston_tracts <- spTransform(boston_tracts, CRS("+init=epsg:2249")) #reproject lattice
#make a grid
lattice <- expand.grid(Long = seq(boston_tracts@bbox[1,1],
boston_tracts@bbox[1,2],length.out = 200),
Lat = seq(boston_tracts@bbox[2,1],
boston_tracts@bbox[2,2],length.out = 200))
dim(lattice)
plot(lattice)
#find if the points are in the region
sp_lattice <- lattice
coordinates(sp_lattice) <- ~Long+Lat
proj4string(sp_lattice) <- proj4string(boston_tracts)
overlap_set <- over(sp_lattice, boston_tracts)
#remove lattice points not in Boston
lattice <- lattice[!(is.na(overlap_set$GEOID)),]
plot(lattice)
#combine with the rest of the Census data
lattice <- cbind(lattice, overlap_set[-which(is.na(overlap_set$GEOID)),])
#check for NAs
sum(is.na(lattice$med_income))
sum(is.na(lattice$total_pop))
#remove observations with no values for med_income
lattice <- lattice %>% filter(!is.na(med_income))
#assign projection to lattice
coordinates(lattice) <- ~Long+Lat
proj4string(lattice) <- proj4string(boston_tracts)
#change from SpatialPointsDataFrame to SpatialPixelsDataFrame
class(lattice)
gridded(lattice) = TRUE
class(lattice)
#then change to SpatialGridDataFrame
lattice_grid <- as(lattice, "SpatialGridDataFrame")
class(lattice_grid)
#make into an "im" object
image(lattice_grid["med_income"]) #plot first
med_income_im <- as(lattice_grid["med_income"], "im") #convert to im
plot(med_income_im)
fit4 <- ppm(Q = entertain_ppp, trend = ~med_income,
covariates = list(med_income = med_income_im))
med_income_im <- rescale(med_income_im, 1000000)
fit4 <- ppm(Q = entertain_ppp, trend = ~med_income,
covariates = list(med_income = med_income_im))
fit4 <- ppm(Q = entertain_ppp, trend = ~med_income,
covariates = list(med_income = med_income_im))
sum(is.na(lattice$med_income))
summary(fit4)
plot(fit4)
plot(fit4, superimpose = F)
image(lattice_grid["total_pop"]) #plot first
total_pop_im <- as(lattice_grid["total_pop"], "im") #convert to im
plot(total_pop_im)
total_pop_im <- rescale(total_pop_im, 1000000)
fit5 <- ppm(Q = entertain_ppp, trend = ~med_income + total_pop,
covariates = list(med_income = med_income_im,
total_pop = total_pop_im))
summary(fit5)
plot(fit5, superimpose = F)
summary(fit4)
plot(fit4, superimpose = F)
summary(fit4)
plot(fit4, superimpose = F)
plot(entertain_ppp, add = T, superimpose = F)
plot(entertain_ppp, add = T, superimpose = F)
plot(entertain_ppp, add = T, superimpose = F)
plot(kernel_density1, main = "KDE: Boston Entertainment License Data")
plot(entertain_ppp, add = T, superimpose = F)
plot(kernel_density1, main = "KDE: Boston Entertainment License Data")
plot(fit4, superimpose = F)
plot(fit5)
summary(fit4)
summary(fit5)
?sample
#plot variogram with simulated variograms to assess for CSR
#Very similar to simulation envelopes
#(this takes a second)
print(xyplot(gamma ~ dist, v, pch = 3, type = 'b', lwd = 2, col = 'darkblue',
panel = function(x, y, ...) {
for (i in 1:100) { #why 100?                      #<--- try changing this
#what is this step doing?
minn_subs$random = sample(minn_subs$FREE_AIR) #<--- what is this doing?
#calculate the variogram to each shuffled dataset
v = variogram(random ~ 1, minn_subs)
#add the line to the plot
llines(v$dist, v$gamma, col = 'grey')
}
panel.xyplot(x, y, ...)
},
ylim = c(50, 500),
xlab = 'distance', ylab = 'semivariance'
))
#Packages:
library(rgdal)
library(spatstat)
library(raster)
library(tigris)
library(ggplot2)
library(broom)
library(tidyverse)
library(ggmap)
library(spdep)
library(lattice)
library(gstat)
library(gridExtra)
#show possibilities
show.vgms()
#variogram of the data
ggplot(data = v, aes(x = dist, y = gamma)) +
geom_point(size = 3)
#create (and store) a variogram for Minnesota data
v <- variogram(FREE_AIR ~ 1, minn_subs)
#start clean
rm(list = ls())
#set the seed
set.seed(3)
#load Minnesota data
minn_data <- read.csv(file = "https://www.math.carleton.edu/ckelling/spat_data/Gravity_Stations_2019.csv")
#a few clear outliers (longitude) in this dataset.... let's remove them
minn_data <- minn_data %>% filter(!LONG_DD > 0)
#let's subset the data to pretend like we only had a smaller number of data
#   points/monitoring stations available to us
minn_subs <- minn_data[runif(n=1000, 1, nrow(minn_data)),]
#convert to spatial points
coordinates(minn_subs) <- ~LONG_DD + LAT_DD
#create (and store) a variogram for Minnesota data
v <- variogram(FREE_AIR ~ 1, minn_subs)
#variogram of the data
ggplot(data = v, aes(x = dist, y = gamma)) +
geom_point(size = 3)
#try seeing how the parameters affect the variogram
vg_param_theor <- variogramLine(vgm(psill = , #<--- enter number
model = ,       #<--- enter type
range = ,       #<--- enter number
nugget = ),     #<--- enter number
maxdist = 3)
?vgm
#variogram of the data
ggplot(data = v, aes(x = dist, y = gamma)) +
geom_point(size = 3)
#show possibilities
show.vgms()
?vgm
#try seeing how the parameters affect the variogram
vg_param_theor <- variogramLine(vgm(psill = 300, #<--- enter number
model = "Pen",       #<--- enter type
range = 0.75,       #<--- enter number
nugget = 10),     #<--- enter number
maxdist = 3)
#plot theoretical variogram
ggplot(data = v, aes(x = dist, y = gamma)) +
geom_point(size = 3) +
geom_line(data = vg_param_theor, aes(x = dist, y = gamma),
col = "blue", size =2) +
xlab("Distance") + ylab("Semivariance") + labs(title = "Theoretical variogram")
#try seeing how the parameters affect the variogram
vg_param_theor <- variogramLine(vgm(psill = 300, #<--- enter number
model = "Pen",       #<--- enter type
range = 1,       #<--- enter number
nugget = 10),     #<--- enter number
maxdist = 3)
#plot theoretical variogram
ggplot(data = v, aes(x = dist, y = gamma)) +
geom_point(size = 3) +
geom_line(data = vg_param_theor, aes(x = dist, y = gamma),
col = "blue", size =2) +
xlab("Distance") + ylab("Semivariance") + labs(title = "Theoretical variogram")
#fit an actual model for a variogram based on your experimentation above
vg_param_actual <- variogramLine(fit.variogram(v, vgm(psill = 300, #<--- enter number
model = "Pen",       #<--- enter type
range = 1,       #<--- enter number
nugget = 10)),    #<--- enter number
maxdist = 3)
#plot actual variogram
ggplot(data = v, aes(x = dist, y = gamma)) +
geom_point(size = 3) +
geom_line(data = vg_param_actual, aes(x = dist, y = gamma),
col = "blue", size =2) +
xlab("Distance") + ylab("Semivariance") + labs(title = "Fitted variogram")
#specify type so you can combine into one dataframe (need this for the legend)
vg_param_theor$Type <- "Initial Values Variogram"
vg_param_actual$Type <- "Fitted Variogram"
full_dat <- bind_rows(vg_param_theor, vg_param_actual)
#plot fitted variogram
ggplot(data = v, aes(x = dist, y = gamma)) +
geom_point(size = 3) +
geom_line(data = full_dat, aes(x = dist, y = gamma, col = Type), size =2) +
xlab("Distance") + ylab("Semivariance") + labs(col = "Variogram Type")
#no initial values
fit.variogram(v, model = vgm("Pen")) #<--- enter type
#with initial values
fit.variogram(v, vgm(psill = 300,   #<--- enter number
model = "Pen",   #<--- enter type
range = 1,   #<--- enter number
nugget = 10)) #<--- enter number
#try seeing how the parameters affect the variogram
vg_param_theor <- variogramLine(vgm(psill = 300, #<--- enter number
model = "Sph",       #<--- enter type
range = 1,       #<--- enter number
nugget = 10),     #<--- enter number
maxdist = 3)
#plot theoretical variogram
ggplot(data = v, aes(x = dist, y = gamma)) +
geom_point(size = 3) +
geom_line(data = vg_param_theor, aes(x = dist, y = gamma),
col = "blue", size =2) +
xlab("Distance") + ylab("Semivariance") + labs(title = "Theoretical variogram")
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(sp)
library(tigris)
library(ggmap)
library(tidycensus)
library(maditr)
library(spdep)
library(spatialreg)
library(gridExtra)
library(sf)
library(spatstat)
load("/Users/ayaklos/Documents/GitHub/carleton_comps_22_23/data/working/Census_Blocks_Data.Rdata")
load("/Users/ayaklos/Documents/GitHub/carleton_comps_22_23/data/working/ward_9_blockgroups/Ward9_Blocks.Rdata")
mn_wards <- st_read("/Users/ayaklos/Documents/GitHub/carleton_comps_22_23/data/original/City_Council_Wards/WARDS.shp")
mn_ward9 <- mn_wards[mn_wards$BDNUM==9,] %>% as_Spatial()
minn_map <- ggmap(get_map(c(left = -93.334, bottom = 44.888,
right = -93.19, top = 45.055), source = "stamen"))
ward9_map <- ggmap(get_map(c(left = -93.28, bottom = 44.933,
right = -93.227, top = 44.963), source = "stamen"))
proj4string(mn_ward9)
mn_ward9 <- spTransform(mn_ward9, CRS("+proj=longlat +datum=NAD83 +no_defs"))
proj4string(mn_ward9)
proj4string(minneapolis_blocks) #check projection
minn_bg_tidy <- broom::tidy(minneapolis_blocks)
minneapolis_blocks$id <- row.names(minneapolis_blocks)
minn_bg_tidy <- left_join(minn_bg_tidy, minneapolis_blocks@data)
proj4string(ward9_blocks) #check projection
ward9_bg_tidy <- broom::tidy(ward9_blocks)
ward9_blocks$id <- row.names(ward9_blocks)
ward9_bg_tidy <- left_join(ward9_bg_tidy, ward9_blocks@data)
proj4string(mn_ward9) #check projection
ward9_tidy <- broom::tidy(mn_ward9)
mn_ward9$id <- row.names(mn_ward9)
ward9_tidy <- left_join(ward9_tidy, mn_ward9@data)
use_of_force_data <- read.csv("/Users/ayaklos/Documents/GitHub/carleton_comps_22_23/data/original/Police_Use_of_Force.csv")
use_of_force_data <- use_of_force_data[use_of_force_data$X != 0,]
crime_data <- read.csv("/Users/ayaklos/Documents/GitHub/carleton_comps_22_23/data/original/Crime_Data.csv")
crime_data <- crime_data[crime_data$X != 0,]
police_incident_data <- read.csv("/Users/ayaklos/Documents/GitHub/carleton_comps_22_23/data/working/Police_Incidents.csv")
police_incident_data <- police_incident_data[police_incident_data$X != 0,]
polygons <- as(minneapolis_blocks, "SpatialPolygons")
poly_one <- st_transform(st_union(st_as_sf(polygons)), crs=CRS("+proj=longlat +datum=NAD83 +no_defs"))
minn_blocks_one <- poly_one %>% as_Spatial()
proj4string(minn_blocks_one) #check projection
minn_one_bg_tidy <- broom::tidy(minn_blocks_one)
minn_blocks_one$id <- row.names(minn_blocks_one)
minn_map +
geom_polygon(data= minn_bg_tidy,
aes(x = long, y = lat, group = group,
fill = total_pop), col = "black") +
geom_polygon(data= ward9_tidy,
aes(x = long, y = lat, group = group),
col = "red", fill = NA, linewidth=2) +
labs(fill = "Total Population",
title = "Total Population by Census Blocks (Minneapolis)") +
theme(axis.title = element_blank(),
axis.text = element_blank(),
axis.ticks = element_blank()) +
scale_fill_distiller(palette = "Spectral")
ward9_map +
geom_polygon(data= ward9_bg_tidy,
aes(x = long, y = lat, group = group,
fill = total_pop), col = "black") +
labs(fill = "Total Population",
title = "Total Population by Census Blocks (Ward 9)") +
theme(axis.title = element_blank(),
axis.text = element_blank(),
axis.ticks = element_blank()) +
scale_fill_distiller(palette = "Spectral")
minn_map +
geom_polygon(data= minn_blocks_one,
aes(x = long, y = lat, group = group),
col = "blue", linewidth=1, fill=NA) +
geom_point(data=use_of_force_data, aes(x=X, y=Y), alpha=0.3, size=1) +
geom_polygon(data= ward9_tidy,
aes(x = long, y = lat, group = group),
col = "red", fill = NA, linewidth=1) +
labs(title = "Police Use of Force Incidents \n in Minneapolis") +
theme(axis.title = element_blank(),
axis.text = element_blank(),
axis.ticks = element_blank())
minn_map +
geom_polygon(data= minn_blocks_one,
aes(x = long, y = lat, group = group),
col = "blue", linewidth=1, fill=NA) +
geom_point(data=crime_data, aes(x=X, y=Y), alpha=0.3, size=1) +
geom_polygon(data= ward9_tidy,
aes(x = long, y = lat, group = group),
col = "red", fill = NA, linewidth=1) +
labs(title = "Crimes in Minneapolis") +
theme(axis.title = element_blank(),
axis.text = element_blank(),
axis.ticks = element_blank())
minn_map +
geom_polygon(data= minn_blocks_one,
aes(x = long, y = lat, group = group),
col = "blue", linewidth=1, fill=NA) +
geom_point(data=police_incident_data, aes(x=Long, y=Lat), alpha=0.3, size=1) +
geom_polygon(data= ward9_tidy,
aes(x = long, y = lat, group = group),
col = "red", fill = NA, linewidth=1) +
labs(title = "Police Incidents in Minneapolis") +
theme(axis.title = element_blank(),
axis.text = element_blank(),
axis.ticks = element_blank())
setwd("/Users/ayaklos/Documents/GitHub/carleton_comps_22_23/src/parker")
minn_wards <- st_read("../../data/original/City_Council_Wards/WARDS.shp") %>%
as_Spatial()
minn_map <- ggmap(get_map(c(left = -93.35, bottom = 44.88,
right = -93.18, top = 45.06), source = "stamen"))
mn_wards <- st_read("../../data/original/City_Council_Wards/WARDS.shp")
ward9 <-st_crop(mn_wards, xmin = -93.28, xmax = -93.227, ymin = 44.933, ymax = 44.963) %>%
as_Spatial()
load("/Users/ayaklos/Documents/GitHub/carleton_comps_22_23/data/working/Census_Blocks_Data.Rdata")
load("/Users/ayaklos/Documents/GitHub/carleton_comps_22_23/data/working/ward_9_blockgroups/Ward9_Blocks.Rdata")
#download ward 9 block groups
load("/Users/ayaklos/Documents/GitHub/carleton_comps_22_23/data/working/ward_9_blockgroups/Ward9_Blocks.Rdata")
cor.dat <- ward9_blocks@data
cor.dat <- cor.dat[,c(20, 32, 37, 39:40, 42)]
colnames(cor.dat) <- c("Median Household Income", "Total Population", "Percent Unemployed", "Percent Foodstamps", "Percent Female", "Herfindahl–Hirschman Index")
cor_dat.mat <- cor(cor.dat)
col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", "#77AADD", "#4477AA"))
corrplot(cor_dat.mat, method="color", col=col(200),
type="upper", order="hclust",
addCoef.col = "black", # Add coefficient of correlation
tl.col="black", tl.srt=45, #Text label color and rotation
diag=FALSE
)
knitr::opts_chunk$set(echo = TRUE)
library(corrplot)
library(tigris)
library(tidycensus)
cor.dat <- ward9_blocks@data
cor.dat <- cor.dat[,c(20, 32, 37, 39:40, 42)]
colnames(cor.dat) <- c("Median Household Income", "Total Population", "Percent Unemployed", "Percent Foodstamps", "Percent Female", "Herfindahl–Hirschman Index")
cor_dat.mat <- cor(cor.dat)
col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", "#77AADD", "#4477AA"))
corrplot(cor_dat.mat, method="color", col=col(200),
type="upper", order="hclust",
addCoef.col = "black", # Add coefficient of correlation
tl.col="black", tl.srt=45, #Text label color and rotation
diag=FALSE
)
knitr::opts_chunk$set(echo = TRUE)
library(corrplot)
library(tigris)
library(tidycensus)
#download ward 9 block groups
load("/Users/ayaklos/Documents/GitHub/carleton_comps_22_23/data/working/ward_9_blockgroups/Ward9_Blocks.Rdata")
cor.dat <- ward9_blocks@data
cor.dat <- cor.dat[,c(20, 32, 37, 39:40, 42)]
colnames(cor.dat) <- c("Median Household Income", "Total Population", "Percent Unemployed", "Percent Foodstamps", "Percent Female", "Herfindahl–Hirschman Index")
cor_dat.mat <- cor(cor.dat)
col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", "#77AADD", "#4477AA"))
corrplot(cor_dat.mat, method="color", col=col(200),
type="upper", order="hclust",
addCoef.col = "black", # Add coefficient of correlation
tl.col="black", tl.srt=45, #Text label color and rotation
diag=FALSE
)
cor.dat <- ward9_blocks@data
cor.dat <- cor.dat[,c(20, 32, 37, 39:40, 42)]
colnames(cor.dat) <- c("Median Household Income", "Total Population", "Percent Unemployed", "Percent Foodstamps", "Percent Female", "Herfindahl–Hirschman Index")
cor_dat.mat <- cor(cor.dat)
col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", "#77AADD", "#4477AA"))
corrplot(cor_dat.mat, method="color", col=col(200),
type="upper", order="hclust",
addCoef.col = "black", # Add coefficient of correlation
tl.col="black", tl.srt=45, #Text label color and rotation
diag=FALSE
)
#load in Minneapolis block groups
load("/Users/ayaklos/Documents/GitHub/carleton_comps_22_23/data/working/Census_Blocks_Data.Rdata")
#load in Ward 9 block groups
load("/Users/ayaklos/Documents/GitHub/carleton_comps_22_23/data/working/ward_9_blockgroups/Ward9_Blocks.Rdata")
#load in Minneapolis wards
mn_wards <- st_read("/Users/ayaklos/Documents/GitHub/carleton_comps_22_23/data/original/City_Council_Wards/WARDS.shp")
mn_ward9 <- mn_wards[mn_wards$BDNUM==9,] %>% as_Spatial() #only ward 9
minn_map <- ggmap(get_map(c(left = -93.334, bottom = 44.888,
right = -93.19, top = 45.055), source = "stamen"))
ward9_map <- ggmap(get_map(c(left = -93.28, bottom = 44.933,
right = -93.227, top = 44.963), source = "stamen"))
proj4string(mn_ward9)
proj4string(mn_ward9)
mn_ward9 <- spTransform(mn_ward9, CRS("+proj=longlat +datum=NAD83 +no_defs"))
proj4string(mn_ward9)
proj4string(minneapolis_blocks) #check projection
minn_bg_tidy <- broom::tidy(minneapolis_blocks)
View(minn_bg_tidy)
minneapolis_blocks$id <- row.names(minneapolis_blocks)
View(minneapolis_blocks@data)
#add polygon coordinates to ward9_blocks
proj4string(ward9_blocks) #check projection
ward9_bg_tidy <- broom::tidy(ward9_blocks)
ward9_blocks$id <- row.names(ward9_blocks)
ward9_bg_tidy <- left_join(ward9_bg_tidy, ward9_blocks@data)
proj4string(mn_ward9) #check projection
ward9_tidy <- broom::tidy(mn_ward9)
mn_ward9$id <- row.names(mn_ward9)
ward9_tidy <- left_join(ward9_tidy, mn_ward9@data)
